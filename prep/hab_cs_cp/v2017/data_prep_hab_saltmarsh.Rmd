---
title: 'OHIBC: data_prep_hab_saltmarsh.Rmd'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(rgdal)
library(rgeos)

source('~/github/ohibc/src/R/common.R')  ### an OHIBC specific version of common.R

dir_git     <- '~/github/ohibc'
dir_spatial <- file.path(dir_git, 'prep/spatial')  ### github: general buffer region shapefiles
dir_anx     <- file.path(dir_M, 'git-annex/bcprep')

### goal specific folders and info
goal      <- 'hab'
scenario  <- 'v2016'
dir_goal  <- file.path(dir_git, 'prep', goal, scenario)
dir_goal_anx <- file.path(dir_anx, goal, scenario)

### provenance tracking
library(provRmd); prov_setup()

### support scripts
source(file.path(dir_git, 'src/R/rast_tools.R')) 
  ### gdal_rast2, plotting

### set up the default BC projection to be BC Albers
p4s_bcalb <- c('bcalb' = '+init=epsg:3005')

```

# Summary

Create saltmarsh layers for HAB, CP, CS goals.  The areas calculated in this script will be used in the goal_prep script to compare area to pressure, and calculate a score.

# Updates from previous assessment

***

# Data Source [NOTE: can be copied from README.md in rawdata file]
**Reference**: [citation for source data; website, literature, contact information. Version of data (if relevant). Screenshots if a series of menus had to be navigated to obtain the data.]

**Downloaded**: [date downloaded or received]

**Description**:  [e.g., surface aragonite state]

**Native data resolution**: [e.g., 1 degree, 30 m, etc.]   

**Time range**: [e.g., 1880-1899, monthly data provided for each year] 

**Format**:  [e.g. NetCDF]

**classifications**:

- 11 Unclassified: Areas not classified due to clouds
- 21 Settlement: Built-up and urban
- 25 Roads: Primary, secondary and tertiary
- 31 Water: Natural and human-made
- 41 Forest: Treed areas >1 ha in size
- 42 Forest Wetland: Wetland with forest cover
- 45 Trees: Treed areas <1 ha in size
- 46 Treed Wetland: Wetland with tree cover
- 51 Cropland: Annual and perennial
- 61 Grassland Managed: Natural grass and shrubs used for cattle grazing
- 62 Grassland Unmanaged: Natural grass and shrubs with no apparent use (forest openings, alpine meadows, tundra, etc.)
- 71 Wetland: Undifferentiated wetland
- 73 Wetland Shrub: Wetland with shrub cover
- 74 Wetland Herb: Wetland with grass cover
- 91 Other land: Rock, beaches, ice, barren land 

***
  
# Methods

Salt Marsh health for status and trend.  For this measure, we will determine rate of salt marsh change within 1 km inland and 3 nm offshore (in some places, wetland cells are indicated that are outside the bounds of the land polygons).  Salt marsh presence will be established using categories 71, 73, and 74 from the Government of Canada 30 m land use rasters for 1990, 2000, and 2010.

In addition to salt marsh, we will also extract forest presence (categories 41, 42, 45, 46) within 1 km of shoreline; this may be an interesting factor to include in the Coastal Protection and Carbon Storage goals.

Urban development (categories 21, 25) may help to identify direct human impact on habitats.

General process: 

- calc coverage in each region for all three years using 1 km inland and 3 nm offshore rasters.
- determine linear trend based on the two points
- backfill all study years based on linear model
- WHAT IS REFERENCE POINT?

- Salt marsh extent for weighting
- To align with seagrass extent, use CEC saltmarsh polygons

## Prepare rasters

Combine three UTM region maps (8, 9, 10) for each of three years (1990, 2000, 2010).  Each raw raster is transformed to BC Albers for equal area projection, and then the three rasters for each year are merged into one complete raster.

``` {r reproject and merge land cover rasters}

### set up pathnames for final rasters
rast_landuse_files <- c('1990' = file.path(dir_goal_anx, 'raster/land_cover_1990_30m.tif'),
                        '2000' = file.path(dir_goal_anx, 'raster/land_cover_2000_30m.tif'),
                        '2010' = file.path(dir_goal_anx, 'raster/land_cover_2010_30m.tif'))
rast_data_dir <- file.path(dir_anx, '_raw_data/gov_of_canada/land_use_90_00_10')

### look for final rasters with no associated file  
rast_landuse_files <- rast_landuse_files[!file.exists(rast_landuse_files)]

for(i in 1:length(rast_landuse_files)) {
  # i <- 2
  
  year <- names(rast_landuse_files[i])
  
  ### find all raster files for this year; there should be three zones
  rast_yr <- list.files(rast_data_dir,
                        full.names = TRUE,
                        pattern = year)
  rast_yr <- rast_yr[str_detect(rast_yr, '.tif$')]
  
  x <- lapply(rast_yr, raster) ### read 'em all in

  ### have to reproject; each is in a different UTC projection, project all to BC Albers
  y <- parallel::mclapply(x, mc.cores = length(x),
    FUN = function(x) {
      projectRaster(x, res = res(x), method = 'ngb', crs = p4s_bcalb,
                    filename = file.path(dir_goal_anx, 'raster', paste0(names(x), '.tif')))
  })
  # x1 <- file.path(dir_goal_anx, 'raster', basename(rast_yr))
  # y <- lapply(x1, raster)
  
  ### merge the reprojected rasters; the origins are off by ~15 m, or about half
  ### the resolution, so tolerance = 0.5 to allow for the mismatch.
  ### Saves completed rasters in git-annex/bcprep/hab/v2016/raster
  z <- raster::merge(y[[1]], y[[2]], y[[3]],
                     tolerance = 0.5,
                     filename = rast_landuse_files[i])
}

```

## Filter rasters to target land uses

The overall land use rasters are cropped to the extents of region polygons (to reduce size and streamline processing).  Land use values not included in the categories for wetlands, forest, or development are changed to NA.

``` {r crop_and_filter_land_use}

cropped_rast_landuse_files <- c('1990' = file.path(dir_goal_anx, 'raster/land_cover_1990_30m_crop.tif'),
                                '2000' = file.path(dir_goal_anx, 'raster/land_cover_2000_30m_crop.tif'),
                                '2010' = file.path(dir_goal_anx, 'raster/land_cover_2010_30m_crop.tif'))

if(any(!file.exists(cropped_rast_landuse_files))) {
  rast_landuse_files <- c('1990' = file.path(dir_goal_anx, 'raster/land_cover_1990_30m.tif'),
                          '2000' = file.path(dir_goal_anx, 'raster/land_cover_2000_30m.tif'),
                          '2010' = file.path(dir_goal_anx, 'raster/land_cover_2010_30m.tif'))
  
  message('Cropping and filtering land use values for: \n  ', paste(rast_landuse_files, collapse = '\n  '))
  
  stack_landuse <- stack(rast_landuse_files)
  
  ### bring in buffer regions to create overall extents
  rgn_poly_3nm <- readOGR(dsn = path.expand(dir_spatial), layer = 'ohibc_offshore_3nm', stringsAsFactors = FALSE)
  rgn_poly_1km <- readOGR(dsn = path.expand(dir_spatial), layer = 'ohibc_inland_1km', stringsAsFactors = FALSE)
  
  bb_max <- pmax(bbox(rgn_poly_3nm), bbox(rgn_poly_1km))
  bb_min <- pmin(bbox(rgn_poly_3nm), bbox(rgn_poly_1km))
  
  ext1 <- extent(bb_min[1, 1], bb_max[1, 2], bb_min[2, 1], bb_max[2, 2])
  
  ### crop rasters to new extents
  stack_landuse_crop <- crop(stack_landuse, ext1)
  
  lc_values <- c(21, 25, 41, 42, 45, 46, 71, 73, 74)
  
  values(stack_landuse_crop)[!values(stack_landuse_crop) %in% lc_values] <- NA
  
  writeRaster(stack_landuse_crop, 
              filename  = str_replace(rast_landuse_files, '.tif', '_crop.tif'),
              bylayer   = TRUE,
              overwrite = TRUE)
  
} else {
  
  message('Cropped and filtered land use values exist at: \n  ', paste(cropped_rast_landuse_files, collapse = '\n  '))

}

```

The cropped and filtered land use values for each year are cross-tabulated to OHIBC regions.  This will be done for both the 1 km inland regions and the 3 nm offshore regions, to catch wetland regions that are identified in estuarine areas (i.e. not inland)

``` {r zonal_stats_landuse_vs_rgn}

zonal_files <- c('1990' = file.path(dir_goal, 'int/land_cover_1990.csv'),
                 '2000' = file.path(dir_goal, 'int/land_cover_2000.csv'),
                 '2010' = file.path(dir_goal, 'int/land_cover_2010.csv'))

### load landuse rasters for missing zonal files
landuse_files <- c('1990' = file.path(dir_goal_anx, 'raster/land_cover_1990_30m_crop.tif'),
                   '2000' = file.path(dir_goal_anx, 'raster/land_cover_2000_30m_crop.tif'),
                   '2010' = file.path(dir_goal_anx, 'raster/land_cover_2010_30m_crop.tif'))
landuse_files <- landuse_files[!file.exists(zonal_files)]

landuse_rasts <- lapply(landuse_files, raster)

### load region rasters
# rast_1km_30m <- raster(file.path(dir_goal_anx, 'raster/ohibc_inland_1km_30m.tif'))
# rast_3nm_30m <- raster(file.path(dir_goal_anx, 'raster/ohibc_offshore_3nm_30m.tif'))

### create a single raster with positive values for 1km inland and
### negative values for 3nm offshore
# rast_rgn <- rast_1km_30m
# values(rast_rgn)[!is.na(values(rast_3nm_30m)] <- -1 * values(rast_3nm_30m)[!is.na(values(rast_3nm_30m))]
# writeRaster(rast_rgn, file.path(dir_goal_anx, 'raster/ohibc_coastal_30m.tif'))
rast_rgn <- raster(file.path(dir_goal_anx, 'raster/ohibc_coastal_30m.tif'))

for(year in names(landuse_rasts)) {
  # year <- names(landuse_rasts)[1]
  ### NOTE: The crosstab function returns this warning - does it affect the
  ### outcomes, or does the function coerce the correct outcome?
      # Warning message:
      # In FUN(X[[i]], ...) : integer overflow - use sum(as.numeric(.))
  
  message('processing coastal zones for land use in ', year)
  
  ptm <- proc.time()
  stats_landuse <- raster::crosstab(landuse_rasts[[year]], rast_rgn, useNA = TRUE, progress = 'text') %>%
    as.data.frame() %>%
    setNames(c('value', 'rgn_id', 'n_cells')) %>%
    mutate(value  = as.integer(as.character(value)),
           rgn_id = as.integer(as.character(rgn_id)),
           year   = as.integer(year),
           ### convert negative rgn ID to offshore zone and positive to inland:
           zone   = ifelse(rgn_id > 0, '1km_inland', '3nm_offshore'),
           rgn_id = abs(rgn_id)) %>%
    arrange(rgn_id)
  message('Elapsed: ', (proc.time() - ptm)[3], ' sec')
  
  write_csv(stats_landuse, zonal_files[year])

} 

```

Once the landuse raster is cross-tabulated against the OHI inland raster we have the number of human landuse cells within each region.  NA values are non-human-landuse.

-----

## Calculate land use change area and total area by region

Grouping by rgn_id, the number of human landuse cells per region is simply the number of non-NA cells; the total number of cells includes both value and NA cells.

Since the cells are 1 hectare, we can easily calculate area by multiplying cell count * 0.01 km^2^ per cell.

``` {r clean_up_zonal_stats, eval = TRUE}

zonal_files <- c('1990' = file.path(dir_goal, 'int/land_cover_1990.csv'),
                 '2000' = file.path(dir_goal, 'int/land_cover_2000.csv'),
                 '2010' = file.path(dir_goal, 'int/land_cover_2010.csv'))

zonal_stats <- lapply(zonal_files, read_csv) %>%
  bind_rows()
  
rgn_names <- foreign::read.dbf(file.path(dir_spatial, 'ohibc_rgn.dbf'),
                               as.is = TRUE) %>%
  dplyr::select(rgn_id, rgn_name)

landuse_codes <- data.frame(value = c(21, 25, 41, 42, 45, 46, 71, 73, 74),
                            desc  = c('settlement', 'roads', rep('forest', 4), rep('wetlands', 3)))

zonal_stats <- zonal_stats %>%
  left_join(rgn_names, by = 'rgn_id') %>%
  left_join(landuse_codes, by = 'value')

### Determine total cells per region (n_cells_tot) and then a cumulative
### total of cells per region; just add 3nm and 1km zones to keep it simple
zonal_stats1 <- zonal_stats %>%
  group_by(rgn_id, rgn_name, year, zone) %>%
  mutate(n_tot = sum(n_cells)) %>%
  group_by(rgn_id, rgn_name, year, desc) %>%
  mutate(n_landuse = sum(n_cells)) %>%
  filter(!is.na(value) & !is.na(rgn_id)) %>%
  filter(zone == '1km_inland') %>%
  ungroup()

### clean up NAs and consolidate land use types
zonal_stats1 <- zonal_stats1 %>%
  select(-value, -n_cells, -zone) %>%
  distinct()

cell_area = 0.03 * 0.03 ### 30 m cells, converted to km^2
zonal_stats2 <- zonal_stats1 %>%
  mutate(a_tot_1km_inland = n_tot * cell_area,
         a_landuse        = n_landuse * cell_area) %>%
  select(-n_tot, -n_landuse)

write_csv(zonal_stats2, file.path(dir_goal, 'int/land_cover_df.csv'))
```

``` {r expand_time_series}

landuse_df <- read_csv(file.path(dir_goal, 'int', 'landuse_stats_1km.csv'))

landuse_ts <- landuse_df %>%
  rename(value_year = year) %>%
  filter(value_year == 2005) %>%
  left_join(data.frame(rgn_id = rep(1:8, times = 21), 
                       year   = rep(1995:2015, each = 8)),
            by = 'rgn_id') ### region 7 drops out - Pacific Offshore

landuse_ts <- landuse_ts %>%
  mutate(a_calc = area_landuse_km2 + area_per_year_km2 * (year - 2005),
         a_calc = ifelse(a_calc < 0, 0, a_calc),
         pct_area    = 100 * a_calc / area_tot_km2) %>%
  dplyr::select(rgn_id, rgn_name, year, landuse, area_calc_km2 = a_calc, area_tot_km2, area_per_year_km2, pct_area)

write_csv(landuse_ts, file.path(dir_goal, 'int', 'landuse_time_series_1km.csv'))

```

  
## Plot scores time series

To examine results, we plot the estimated status and trend over time.

``` {r spp_plot_scores_over_time, fig.height = 4, fig.width = 6, fig.align = 'center'}
library(ggplot2)
library(plotly)

landuse_ts <- read_csv(file.path(dir_goal, 'int', 'landuse_time_series_1km.csv'))

landuse_plot <- ggplot(landuse_ts %>%
                         filter(!is.na(year)),
                       aes(x = year, y = pct_area, group = rgn_name)) +
  ggtheme_plot +
  geom_point(aes(shape = landuse)) +
  geom_line(aes(color = rgn_name, group = landuse), size = 1, alpha = 1) +
  scale_colour_brewer(palette = 'PRGn') +
  labs(x = 'year',
       y = 'Percent of area as human landuse',
       color = 'Region')

ggplotly(landuse_plot)

```
  
# Salt marsh extent for mapping and weighting

``` {r create_bluecarbon_saltmarsh_raster, eval = TRUE}

saltmarsh_rast_file <- file.path(dir_goal_anx, 'tif/bluecarbon_saltmarsh.tif') %>%
  path.expand()

saltmarsh_poly_file <- file.path(dir_anx, '_raw_data/cec/BlueCarbon_SHP',
                                'NA_BlueCarbon/data',
                                'Saltmarsh/na_saltmarsh_areas_08FEB2015.shp') %>%
  path.expand()

if(!file.exists(saltmarsh_rast_file)) {
  
  base_rast <- raster(rast_base_file)
  
  ### contains polys for all of North America.  Read it in; filter to just Canada BC; reproject
  saltmarsh_poly <- readOGR(dsn = path.expand(dirname(saltmarsh_poly_file)),
                           layer = basename(saltmarsh_poly_file) %>% str_replace('.shp$', ''))
  saltmarsh_poly_bc <- saltmarsh_poly[saltmarsh_poly@data$STATE_ABB == 'CA-BC', ]
  saltmarsh_poly_bcalb <- spTransform(saltmarsh_poly_bc, base_rast@crs)
  writeOGR(saltmarsh_poly_bcalb, 
           dsn    = path.expand(file.path(dir_goal_anx, 'shp')),
           layer  = 'bluecarbon_saltmarsh',
           driver = 'ESRI Shapefile')
  
  gdal_rast2(src = file.path(dir_goal_anx, 'shp/bluecarbon_saltmarsh.shp'), 
             base_rast, saltmarsh_rast_file, value = 'OBJECTID', override_p4s = TRUE)
  
} else {
  
  git_prov(saltmarsh_poly_file, filetype = 'input')
  git_prov(rast_base_file, filetype = 'input') ### base raster
  git_prov(saltmarsh_rast_file, filetype = 'output')
 
}

```

After creating blue carbon saltmarsh raster, tabulate saltmarsh area per OHIBC region. This CSV stored in github.

``` {r crosstab_saltmarsh_vs_rgns}

saltmarsh_rgns_file <- file.path(dir_goal, 'int', 'bluecarbon_saltmarsh_area.csv')

if(!file.exists(saltmarsh_rgns_file)) {
  saltmarsh_rast <- raster(file.path(dir_goal_anx, 'tif', 'bluecarbon_saltmarsh.tif')) %>%
    setNames('saltmarsh')
  
  rgn_rast <- raster(rast_base_file) %>%
    setNames('rgn_id')
  
  saltmarsh_df <- raster::crosstab(saltmarsh_rast, rgn_rast, 
                                   long = TRUE, useNA = TRUE,
                                   progress = 'text') %>%
    group_by(rgn_id) %>%
    mutate(area_tot = sum(Freq) * .01) %>%   ### get total area in region
    filter(!is.na(saltmarsh) & !is.na(rgn_id)) %>%
    group_by(rgn_id, area_tot) %>%
    summarize(area_saltmarsh = sum(Freq) * .01) ### get just saltmarsh area in region
  
  
  write_csv(saltmarsh_df, saltmarsh_rgns_file)

} else {
  
  git_prov(file.path(dir_goal_anx, 'tif', 'bluecarbon_saltmarsh.tif'), filetype = 'input')
  git_prov(rast_base_file, filetype = 'input')
  git_prov(saltmarsh_rgns_file, filetype = 'output')
}

```

***

# Citation information  
[citation information: include if these data will have their own specific citation.]

***

``` {r prov_footer, results = 'asis'}
prov_wrapup()
```

