---
title: 'OHIBC: data prep for wild-capture fisheries'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(sp)
library(rgdal)
library(raster)
library(DT)

dir_git <- '~/github/ohibc'
source(file.path(dir_git, 'src/R/common.R'))  ### an OHIBC specific version of common.R
dir_rgn <- file.path(dir_git, 'prep/regions')  ### github: general buffer region shapefiles
dir_anx <- file.path(dir_M, 'git-annex/bcprep')


### goal specific folders and info
goal      <- 'fis'
scenario  <- 'v2017'
dir_goal  <- file.path(dir_git, 'prep', goal, scenario)
dir_goal_anx <- file.path(dir_anx, goal, scenario)
dir_spatial  <- file.path(dir_git, 'prep/spatial')
dir_dfo_data <- file.path(dir_anx, '_raw_data/dfo_khunter')


### provenance tracking
library(provRmd); prov_setup()

### support scripts
source(file.path(dir_git, 'src/R/rast_tools.R')) 
  ### raster plotting and analyzing scripts

### set up proj4string options: BC Albers and WGS84
p4s_wgs84 <- '+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0'
p4s_bcalb <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'

```

# Summary
[general description: What data are being generated? Why (what project, etc.)? Upstream/downstream processing information that might be helpful?  Other information?]

# Updates from previous assessment
[Any significant changes in methods from previous analyses?]

***

# Data Source [NOTE: can be copied from README.md in rawdata file]
**Reference**: [citation for source data; website, literature, contact information. Version of data (if relevant). Screenshots if a series of menus had to be navigated to obtain the data.]

**Downloaded**: [date downloaded or received]

**Description**:  [e.g., surface aragonite state]

**Native data resolution**: [e.g., 1 degree, 30 m, etc.]   

**Time range**: [e.g., 1880-1899, monthly data provided for each year] 

**Format**:  [e.g. NetCDF]

***
  
# Methods

Spatialize catch for fisheries.  Each fishery layer will be rasterized to 1 km cells, with values of catch normalized by total area within each reporting block.  For fisheries with distinct RAM stock areas, the catch will be allocated according to these RAM areas to facilitate scoring of stock status per area.

The resulting rasters will then be used to determine allocation to each OHIBC region.

## Determine fisheries to analyze

For all the DFO fisheries data, we need to know how the data is spatialized.  For some fisheries, data is reported as 4 x 4 km cells; for others it may be different. We will generate a lookup table of each fishery with info on year span, catch reporting field, spatial notes, and whether to include it in the analysis.

``` {r get fisheries folders, eval = FALSE}

dir_list <- list.files(file.path(dir_dfo_data, 'd2016/fisheries'), full.names = TRUE)

dir_list <- dir_list[file.info(dir_list)$isdir]

# basename(dir_list)
field_df <- data.frame()
for (i in dir_list) { ### i <- dir_list[2]
  dbfs <- list.files(i, full.names = TRUE, pattern = '.dbf')
  if(length(dbfs) == 0) {
    tmp_df1 <- data.frame(fishery = basename(i),
                          shp     = NA,
                          fields  = NA,
                          values  = NA)
  } else {
    tmp_df1 <- data.frame()
    for(j in dbfs) { ### j <- dbfs[1]
      df <- foreign::read.dbf(file.path(j))
      x <- paste(names(df), collapse = ', ')
      y <- paste(df[1, ], collapse = ', ')
      tmp_df2 <- data.frame(fishery = basename(i),
                            shp     = basename(j) %>% str_replace('\\.dbf$', ''),
                            fields  = x,
                            values  = y)
      tmp_df1 <- bind_rows(tmp_df1, tmp_df2)
    }
  }
  
  field_df <- bind_rows(field_df, tmp_df1)
  
}

dir_df <- data.frame(fish_dir = dir_list) %>%
  mutate(fishery = basename(fish_dir)) %>%
  left_join(field_df, by = 'fishery')
write_csv(dir_df, file.path(dir_goal, 'raw/fish_files_include_raw.csv'))

```


## Generate required spatial files

* OHIBC region raster at 1000 m
* RAM DFO regions polygons
    * This will be used to create a lookup of RAM DFO regions to OHIBC regions, incl. area,
    * or possibly to mask rasters
* rasterize catch to 1000 m; 
    * NOTE: catch IS NOT normalized by area (divide by 16 for 4 x 4 km cells); since we are working with relative weighting across regions, relative weight (or units of weight) will drop out of the calculations.  Normalizing just adds an additional slow step.


``` {r setup_single_harvest_rasters}

fish_files_single <- read_csv(file.path(dir_goal, 'raw/fish_files_include.csv')) %>%
  filter(include == TRUE) %>%
  filter(!is.na(tot_catch_field))

rast_rgn <- raster(file.path(dir_git, 'prep/spatial/raster/ohibc_rgn_raster_1000m.tif'))

for(shp_id in unique(fish_files_single$shp)) {
  ### loop through each fishery directory
  # shp_id <- fish_files_single$shp[1]
  shp_info <- fish_files_single %>%
    filter(shp == shp_id)
  if(nrow(shp_info) > 1) stop('Duplicate shapefile names detected')
  
  shp_file   <- file.path(shp_info$fish_dir, shp_id)
  shp_field  <- shp_info$catch_field
  shp_reproj <- shp_info$reproject
  stock_name <- str_replace_all(shp_info$fishery, '[0-9_]', '') %>%
    paste0('_', shp_info$year)
  
  message('Processing ', shp_id, ' to ', stock_name)
  message('  Projection: ', readLines(paste0(shp_file, '.prj')))
  
  if(shp_reproj) {
    message('  ... reprojecting')
    tmp_shp <- readOGR(dsn = dirname(shp_file),
                       layer = basename(shp_file)) %>%
      spTransform(crs(rast_rgn))
    writeOGR(tmp_shp, 
             dsn = dirname(shp_file),
             layer = paste0(basename(shp_file), '_reproj'),
             overwrite_layer = TRUE)
    shp_file <- file.path(dirname(shp_file), paste0(basename(shp_file), '_reproj'))
    message('  New projection: ', readLines(paste0(shp_file, '.prj')))
  }
  
  output_rast <- file.path(dir_goal_anx, 'fis_rasts', paste0(stock_name, '.tif'))
  
  rast <- gdal_rast2(src = shp_file,
                     rast_base = rast_rgn,
                     dst = output_rast,
                     value = shp_field,
                     override_p4s = TRUE)
  
  if(shp_reproj) {
    message('  ... unlinking temp shapefile ', shp_file)
    if(str_detect(shp_file, 'reproj')) unlink(shp_file)
  }

}

```

``` {r setup_multiple_harvest_rasters}

fish_files_mult <- read_csv(file.path(dir_goal, 'raw/fish_files_include.csv')) %>%
  filter(include == TRUE) %>%
  filter(!is.na(mult_catch_fields))

rast_rgn <- raster(file.path(dir_git, 'prep/spatial/raster/ohibc_rgn_raster_1000m.tif'))

for(shp_id in unique(fish_files_mult$shp)) {
  ### loop through each fishery directory
  # shp_id <- fish_files_mult$shp[1]
  shp_info <- fish_files_mult %>%
    filter(shp == shp_id)
  if(nrow(shp_info) > 1) stop('Duplicate shapefile names detected')
  
  shp_file   <- file.path(shp_info$fish_dir, shp_id)
  shp_fields  <- shp_info$mult_catch_fields %>%
    str_split(' ') %>% unlist()
  shp_reproj <- shp_info$reproject
  
  message('Processing ', shp_id)
  message('  Projection: ', readLines(paste0(shp_file, '.prj')))
  
  if(shp_reproj) {
    message('  ... reprojecting')
    tmp_shp <- readOGR(dsn = dirname(shp_file),
                       layer = basename(shp_file)) %>%
      spTransform(crs(rast_rgn))
    writeOGR(tmp_shp, 
             dsn = dirname(shp_file),
             layer = paste0(basename(shp_file), '_reproj'),
             overwrite_layer = TRUE)
    shp_file <- file.path(dirname(shp_file), paste0(basename(shp_file), '_reproj'))
    message('  New projection: ', readLines(paste0(shp_file, '.prj')))
  }
  
  for(shp_field in shp_fields) {
    ### shp_field <- shp_fields[1]
    message('processing ', shp_field, ' in ', shp_id)
    stock_name <- str_replace_all(shp_info$fishery, '[0-9_]', '') %>%
      paste0('_', tolower(shp_field), '_', shp_info$year)

    output_rast <- file.path(dir_goal_anx, 'fis_rasts', paste0(stock_name, '.tif'))
  
    rast <- gdal_rast2(src = shp_file,
                       rast_base = rast_rgn,
                       dst = output_rast,
                       value = shp_field,
                       override_p4s = TRUE)
  }
  
  if(shp_reproj) {
    message('  ... unlinking temp shapefile ', shp_file)
    if(str_detect(shp_file, 'reproj')) unlink(shp_file)
  }

}

```

* Catch is summed across all years of data for each fishery group
    * mean, rather than year-by-year, would avoid issues with non-overlapping year spans
    * mean also smooths out uneven harvests from year-to-year and cell-to-cell
    * sum will be adequate since we're looking at relative weight.  mean() might drop NAs rather than counting as zero...

``` {r sum_catch_across_years}

rast_list <- list.files(file.path(dir_goal_anx, 'fis_rasts'), pattern = '.tif$', full.names = TRUE)

rast_groups <- rast_list %>%
  basename() %>%
  str_replace('_[0-9]{4}.tif', '') %>%
  unique()

rast_groups <- rast_groups[!str_detect(rast_groups, '^tot')]

for(gp in rast_groups) {
  # gp <- rast_groups[1]

  gp_rasts <- list.files(file.path(dir_goal_anx, 'fis_rasts'), 
                         pattern = paste0('^', gp, '_[0-9]{4}'), 
                         full.names = TRUE)

  cat(c('Processing ', gp, ': \n  ', paste(basename(gp_rasts), collapse = ', '), '\n'))
  
  years    <- basename(gp_rasts) %>% 
    str_extract('[0-9]{4}') %>%
    as.integer()
  
  gp_stack <- raster::stack(gp_rasts)
  
  cat('... summing across all years\n')
  gp_sum <- raster::calc(gp_stack, sum, na.rm = TRUE)
  
  rast_file <- paste0('tot_', gp, '_', min(years), '-', max(years), '.tif')
  
  cat(c('... Writing sum of ', gp, ' catch to ', rast_file, '\n'))
  writeRaster(gp_sum, 
              file.path(dir_goal_anx, 'fis_rasts', rast_file), 
              overwrite = TRUE)
  
}

```

## Associate DFO fishery data with RAM stocks

Most of these DFO fishery datasets do not align directly with RAM stocks.  Here is a lookup of DFO fishery datasets aligned to available RAM stocks:

`r DT::datatable(read_csv(file.path(dir_goal, 'raw', 'dfo_to_ram_ids.csv')))`


``` {r aggregate_to_rgn, eval = FALSE}
if(!exists('rast_rgn'))
  rast_rgn <- raster(file.path(dir_git, 'prep/spatial/ohibc_rgn_raster_1000m.tif'))

dir_rast <- file.path(dir_anx, goal, scenario, 'spatial')

zonestats <- function(stock, value, yrs, fun = 'sum') {
  fis_df <- data.frame()
  for (yr in yrs) { # yr <- 2001
    tmp_rast <- raster(file.path(dir_rast, sprintf('%s%s_%s.tif', stock, yr, value)))
    tmp_zonal <- zonal(tmp_rast, rast_rgn, fun = fun, digits=0, na.rm=TRUE) %>%
      as.data.frame()
    fis_df <- bind_rows(tmp_zonal, fis_df)
  }
names(fis_df) <- c('rgn_id', value, 'year')
return(fis_df)
}

### dungeness crabs!
fis_stock <- 'crabtrap_dungeness'
fis_value <- 'catch_kg'
fis_fun   <- 'sum'
yrs <- c(2001:2011)

catch_df  <- zonestats(fis_stock, 'catch_kg',  yrs, fis_fun)
effort_df <- zonestats(fis_stock, 'effort_hr', yrs, fis_fun)
write_csv(catch_df, file.path(dir_goal, sprintf('int/%s_catch_kg.csv', fis_stock)))
write_csv(effort_df, file.path(dir_goal, sprintf('int/%s_effort_hr.csv', fis_stock)))

### Geoduck!
fis_stock <- 'dive_geoduck'
fis_fun   <- 'sum'
yrs <- c(2003:2011)

catch_df  <- zonestats(fis_stock, 'catch_kg',  yrs, fis_fun)
effort_df <- zonestats(fis_stock, 'effort_hr', yrs, fis_fun)
write_csv(catch_df, file.path(dir_goal, sprintf('int/%s_catch_kg.csv', fis_stock)))
write_csv(effort_df, file.path(dir_goal, sprintf('int/%s_effort_hr.csv', fis_stock)))

### Spot prawns!
fis_stock <- 'prawntrap_prawns'
fis_fun   <- 'sum'
yrs <- c(2001:2002)

catch_df  <- zonestats(fis_stock, 'catch_kg',  yrs, fis_fun)
effort_df <- zonestats(fis_stock, 'effort_trp', yrs, fis_fun)
write_csv(catch_df, file.path(dir_goal, sprintf('int/%s_catch_kg.csv', fis_stock)))
write_csv(effort_df, file.path(dir_goal, sprintf('int/%s_effort_trp.csv', fis_stock)))

### Sardines!
fis_stock <- 'sardines'
fis_fun   <- 'sum'
yrs <- c(2002:2004)
  
catch_df  <- zonestats(fis_stock, 'sum_estton',  yrs, fis_fun)
write_csv(catch_df, file.path(dir_goal, sprintf('int/%s_catch_estton.csv', fis_stock)))

```


-----

``` {r provenance, results = 'asis'}
prov_wrapup(commit_outputs = FALSE)
```
